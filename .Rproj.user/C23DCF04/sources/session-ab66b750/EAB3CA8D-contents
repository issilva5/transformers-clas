---
title: "Classificação de texto"
subtitle: "PLN - Aprendizagem supervisionada"
author: "Ítallo Silva"
format: revealjs
df-print: paged
from: markdown+emoji
jupyter: python3
---


## Recapitulando

Nas últimas aulas da disciplina, vocês foram apresentados a alguns modelos de aprendizagem supervisionada:

::: incremental
-   Regressão Logística
-   Naive Bayes
-   Redes Neurais Multicamadas
:::

::: fragment
Hoje, nós iremos ver como podemos usar esses modelos para resolver duas tarefas comuns em PLN: **Análise de sentimentos** e **Reconhecimento de entidade mencionada (Named Entity Recognition - NER)**.
:::

# Análise de sentimentos

## Análise de sentimentos

Análise de sentimentos é o processo de analisar um texto digital para determinar se o tom emocional da mensagem é positivo, neutro ou negativo.

::: columns
::: {.column width="30%"}
::: fragment
::: {style="text-align: center"}
:grinning:

Minha experiência até então tem sido [fantátisca!]{style="background-color: #e2fade"}

[**Positivo**]{style="color: green"}
:::
:::
:::

::: {.column width="30%"}
::: fragment
::: {style="text-align: center"}
:neutral_face:

O produto é [ok, eu acho.]{style="background-color: #faf9de"}

[**Neutro**]{style="color: yellow"}
:::
:::
:::

::: {.column width="30%"}
::: fragment
::: {style="text-align: center"}
:angry:

O time de suporte é [horrível!]{style="background-color: #fadede"}

[**Negativo**]{style="color: red"}
:::
:::
:::
:::

## Obtenção dos dados

Os dados são compostos por 3000 comentários sobre diferentes marcas no Twitter.

```{python}
#| echo: true

import pandas as pd
data = pd.read_csv('https://gist.githubusercontent.com/issilva5/993ff7c0d82fa3db85396740aaedbf63/raw/54242a8540a8c048775957f0f609ee5c774966bb/tweets.csv')
```

Vamos dar uma olhada nos dados.

::: {style="width: 100%; height: 50%; overflow: scroll"}
```{python}
data[['sentiment', 'text']].head(10)
```
:::

## Processamento dos dados

```{python}
#| output: false

import re
import nltk.corpus
from unidecode                        import unidecode
from nltk.tokenize                    import word_tokenize
from nltk                             import SnowballStemmer

nltk.download('stopwords')
nltk.download('punkt')

# removes a list of words (ie. stopwords) from a tokenized list.
def removeWords(listOfTokens, listOfWords):
    return [token for token in listOfTokens if token not in listOfWords]

# applies stemming to a list of tokenized words
def applyStemming(listOfTokens, stemmer):
    return [stemmer.stem(token) for token in listOfTokens]

# removes any words composed of less than 2 or more than 21 letters
def twoLetters(listOfTokens):
    twoLetterWord = []
    for token in listOfTokens:
        if len(token) <= 2 or len(token) >= 21:
            twoLetterWord.append(token)
    return twoLetterWord

def processCorpus(corpus, language):
    stopwords = nltk.corpus.stopwords.words(language)
    param_stemmer = SnowballStemmer(language)

    for document in corpus:
        index = corpus.index(document)
        corpus[index] = corpus[index].replace(u'\ufffd', '8')   # Replaces the ASCII '�' symbol with '8'
        corpus[index] = corpus[index].replace(',', '')          # Removes commas
        corpus[index] = corpus[index].rstrip('\n')              # Removes line breaks
        corpus[index] = corpus[index].casefold()                # Makes all letters lowercase

        corpus[index] = re.sub('\W_',' ', corpus[index])        # removes specials characters and leaves only words
        corpus[index] = re.sub("\S*\d\S*"," ", corpus[index])   # removes numbers and words concatenated with numbers IE h4ck3r. Removes road names such as BR-381.
        corpus[index] = re.sub("\S*@\S*\s?"," ", corpus[index]) # removes emails and mentions (words with @)
        corpus[index] = re.sub(r'http\S+', '', corpus[index])   # removes URLs with http
        corpus[index] = re.sub(r'www\S+', '', corpus[index])    # removes URLs with www

        listOfTokens = word_tokenize(corpus[index])
        twoLetterWord = twoLetters(listOfTokens)

        listOfTokens = removeWords(listOfTokens, stopwords)
        listOfTokens = removeWords(listOfTokens, twoLetterWord)

        listOfTokens = applyStemming(listOfTokens, param_stemmer)

        corpus[index]   = " ".join(listOfTokens)
        corpus[index] = unidecode(corpus[index])

    return corpus

corpus = processCorpus(data['text'].tolist(), 'english')
```


Aplicaremos um pipeline de processamento similar ao que fizemos anteriormente:

- Tokenização
- Remoção de símbolos indesejados
- Remoção de stopwords
- Remoção de palavras muito pequenas
- Stemming

## Processamento dos dados

Resultando em:

```{python}
print('Texto original:', data['text'].tolist()[563])
print()
print('Texto processado:', corpus[563])
print()
print('-'*12)
print()
print('Texto original:', data['text'].tolist()[1876])
print()
print('Texto processado:', corpus[1876])
```

## Vetorização do texto

Antes de seguirmos para o treinamento dos modelos precisaremos vetorizar o texto:

```{python}
#| echo: true

from sklearn.feature_extraction.text  import TfidfVectorizer

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(corpus)
y = data['sentiment'].to_numpy()
```

::: fragment

E separá-lo em treino e teste:

```{python}
#| echo: true

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7)
```

:::

## Treinamento dos modelos

```{python}
#| echo: true

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.neural_network import MLPClassifier

clr = LogisticRegression(random_state=0).fit(X_train, y_train)
cnb = MultinomialNB().fit(X_train, y_train)
cmlp = MLPClassifier(random_state=0, max_iter=300, hidden_layer_sizes=(128,16,)).fit(X_train, y_train)
```

## Fazendo predições

Para fazer predições usaremos a função *.predict*:

::: fragment
```{python}
#| echo: true
# Regressão Logística
clr.predict(X_test)[:10]
```
:::

::: fragment
```{python}
#| echo: true
# Naive Bayes
cnb.predict(X_test)[:10]
```
:::

::: fragment
```{python}
#| echo: true
# Multi Layer Perceptron
cmlp.predict(X_test)[:10]
```
:::

## Fazendo predições

É possível também obter a probabilidade de cada classe usando *.predict_proba*:

::: fragment
```{python}
#| echo: true
# Regressão Logística
clr.predict_proba(X_test)[:2]
```
:::

::: fragment
```{python}
#| echo: true
# Naive Bayes
cnb.predict_proba(X_test)[:2]
```
:::

::: fragment
```{python}
#| echo: true
# Multi Layer Perceptron
cmlp.predict_proba(X_test)[:2]
```
:::

# Nossos modelos são bons?

## Métricas

::: {style="font-size: 0.8em"}
Temos algumas métricas que podemos avaliar os modelos que geramos e sua acertividade.

::: incremental
- Acurácia: a quantidade de acertos do nosso modelo divido pelo total da amostra, ou seja, o quão certo meu modelo está?
- Precisão: de todos os dados classificados como positivos, quantos são realmente positivos?
- Recall: quantos positivos foram realmente classificados como positivos?
- F1-score: essa métrica une precisão e recall afim de trazer um número único que determine a qualidade geral do nosso modelo.
:::

:::

## Matriz de confusão

A matriz de confusão fornece um meio de avaliar o êxito de um problema de classificação e onde ele comete erros (ou seja, onde ele se torna "confuso"). A partir dela, podemos derivar as métricas que falamos no slide anterior:

::: {style="display: block;margin-left: auto;margin-right: auto;width: 50%;"}
![](https://learn.microsoft.com/pt-br/dynamics365/finance/finance-insights/media/tn-fn.png)
:::

## Derivando as métricas

::: columns
::: {.column width="50%"}
::: fragment
$$
Acc = \frac{TP + TN}{TP + TN + FP + FN}
$$
:::

::: fragment
$$
Recall = \frac{TP}{TP + FN}
$$
:::
:::

::: {.column width="50%"}
::: fragment

$$
Precision = \frac{TP}{TP + FP}
$$

:::

::: fragment
$$
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
$$

:::
:::
:::

## Plotando a matriz de confusão

A função a seguir cria um plot da matriz de confusão:

```{python}
#| echo: true

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(y_true, y_pred, labels=None, perc=True) -> None:
    cm = confusion_matrix(y_true, y_pred, labels=labels)

    plt.figure(figsize=(len(labels), len(labels)))
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=labels,
        yticklabels=labels,
    )
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()
```

## Plotando a matriz de confusão

::: columns
::: {.column width="30%"}
::: fragment
::: {style="text-align: center"}
Reg. Logística

```{python}
plot_confusion_matrix(y_test, clr.predict(X_test), labels=['Negative', 'Positive'])
```

:::
:::
:::

::: {.column width="30%"}
::: fragment
::: {style="text-align: center"}
Naive Bayes

```{python}
plot_confusion_matrix(y_test, cnb.predict(X_test), labels=['Negative', 'Positive'])
```

:::
:::
:::

::: {.column width="30%"}
::: fragment
::: {style="text-align: center"}
MLP

```{python}
plot_confusion_matrix(y_test, cmlp.predict(X_test), labels=['Negative', 'Positive'])
```

:::
:::
:::
:::

::: fragment
Vamos calcular algumas métricas.
:::

## Relatório de classificação

O sklearn fornece uma função que retorna um resumo das métricas de classificação:

```{python}
from sklearn.metrics import classification_report
```


```{python}
#| echo: true
# Regressão Logística
print(classification_report(y_test, clr.predict(X_test)))
```

----

```{python}
#| echo: true
# Naive Bayes
print(classification_report(y_test, cnb.predict(X_test)))
```

```{python}
#| echo: true
# MLP
print(classification_report(y_test, cmlp.predict(X_test)))
```

# Named Entity Recognition - NER

## Named Entity Recognition - NER

::: {style="font-size: 0.75em"}
::: incremental
- NER é uma atividade que consiste em identificar e categorizar informações-chave (entidades) em textos. 
- Uma entidade pode ser qualquer palavra ou série de palavras que se referem ao mesmo tema. 
- Cada entidade detectada é classificada em uma categoria predeterminada. Por exemplo, as entidades podem ser nomes de pessoas, organizações, locais, horários, quantidades, valores monetários, porcentagens, entre outros.
:::
:::

::: fragment
![](https://miro.medium.com/v2/resize:fit:1400/0*gmPqA8rmGucoeBpH.png)
:::

## Obtendo os dados

Usaremos um dado de frases com tags de entidade.

```{python}
df = pd.read_csv("https://github.com/susanli2016/NLP-with-Python/raw/master/data/ner_dataset.csv", encoding = "ISO-8859-1")
df = df[:50000]
df = df.fillna(method='ffill')
```

::: {style="width: 100%; height: 50%; overflow: scroll"}
```{python}
df.head(20)
```
:::

## Analisando os dados

A seguir podemos ver a quantidade de setenças, palavras e tags únicas.

```{python}
#| echo: true

df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique()
```

Assim como a distribuição das tags:

```{python}
#| echo: true
#| output: false

df.groupby('Tag').size().reset_index(name='counts')
```

::: {style="width: 100%; height: 50%; overflow: scroll"}
```{python}
df.groupby('Tag').size().reset_index(name='counts')
```
:::

## Vetorizando e dividindo os dados

A seguir iremos vetorizar e separar os dados em treino e teste:

```{python}
#| echo: true

from sklearn.feature_extraction import DictVectorizer
import numpy as np

X = df.drop('Tag', axis=1)
v = DictVectorizer(sparse=False)
X = v.fit_transform(X.to_dict('records'))

y = df.Tag.values

classes = np.unique(y).tolist()

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state=0)
```

## Treinando modelos

```{python}
#| echo: true

clr = LogisticRegression(random_state=0).fit(X_train, y_train)
cnb = MultinomialNB().fit(X_train, y_train)
cmlp = MLPClassifier(random_state=0, max_iter=15, hidden_layer_sizes=(128,16,)).fit(X_train, y_train)
```

## Avaliando os modelos

```{python}
#| echo: true
# Regressão Logística
print(classification_report(y_test, clr.predict(X_test)))
```

## Avaliando os modelos

```{python}
#| echo: true
# Naive Bayes
print(classification_report(y_test, cnb.predict(X_test)))
```

## Avaliando os modelos

```{python}
#| echo: true
# MLP
print(classification_report(y_test, cmlp.predict(X_test)))
```

# Dúvidas?